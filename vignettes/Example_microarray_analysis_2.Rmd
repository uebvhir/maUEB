---
title: "Example of workflow for microarray analysis using maUEB package"
author: "Mireia Ferrer, Esther Camacho, Ricardo Gonzalo and Alex Sanchez. UEB."
date: '`r Sys.Date()`'
output: 
    BiocStyle::html_document:
        toc_float:
            collapsed: true
            smooth_scroll: false
vignette: >
  %\VignetteIndexEntry{Example_microarray_analysis}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

<!-- Perque compili necessita la versio antiga de knitr, sino el BiocStyle no funciona -->

```{r, include = FALSE}
# knitr::opts_chunk$set(collapse = TRUE,  comment = "#>")
# knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

The `maUEB` package contains functions to analyze data from microarray experiments. This vignette shows an example of use of `maUEB` package to run a complete microarray analysis. The workflow includes the following steps:

1. Initialization
    + set up project directories
    + load required packages
    + set up the global parameters of the study
    + prepare the targets dataframe
2. Data for the analysis
    + Sample data: load the targets dataframe
    + Microarray data: read or load raw data
3. Data preprocessing and Quality Control
    + Quality control of raw data
    + Background substraction, normalization and summarization
    + Quality Control of normalized data and sources of variability
    + Filtering
4. Differential expression analysis
    + Top tables
    + Volcano plots
5. Multiple comparisons analysis
    + Venn diagrams
    + Expression profiles
6. Analysis of Biological Significance
    + GO analysis
    + Reactome analysis

<!-- The table below summarizes the functions contained in this package: -->

```{r eval=FALSE, include=FALSE}
require(maUEB)
# a <- lsf.str("package:maUEB")
functionsnames <- ls("package:maUEB")
functionsdf <- data.frame(matrix(nrow=length(functionsnames), ncol=3, dimnames=list(NULL,c("FunctionName","FunctionDescription", "FunctionParameters"))))
functionsdf[, "FunctionName"] <- as.character(functionsnames)
for (i in 1:nrow(functionsdf)){
    fun <- functionsdf[i,"FunctionName"]
    pars <- unlist(as.list(args(fun)))
    functionsdf[i,"FunctionParameters"] <- paste(mapply(function(x,y) paste0(x,y,collapse="="), x=names(pars), y=pars), collapse=", ")
}
#intentar q mostri els parametres per defecte
functionparameters <- sapply(functionsnames, args)
a<-lapply(functionparameters, function(x) x[[1]][,2])
x <- library(help="maUEB")
functiondescriptors <- x$info[[2]]
strsplit(functiondescriptors, "\n")
f <- system.file("INDEX", package="maUEB")
b <- cat(readLines(f), sep="\n")
a<-readLines(file.path(find.package("maUEB"), "INDEX"))
a<-strsplit(a, "\n")
```

# Example data

The example is based on a study deposited in the [Gene Expression Omnibus](https://www.ncbi.nlm.nih.gov/geo/) (GEO) and published in ref. The study is based on 12 samples hybridized in Clariom S Mouse Arrays from _Thermofisher_. The experiment condition considered in this study is:

* Treatment:
    + 4 samples from untreated mice (*CTL*)
    + 4 samples from mice treated with PD1 (*PD1*)
    + 4 samples from mice treated with CMP (*CMP*)

For illustration purposes, an imaginary Batch factor will be added to the sample data.

The following group of comparisons will be performed to determine the effects of each treatment on gene expression:

* Effect of Treatment:
    + PD1vsCTL = PD1 - CTL
    + CMPvsCTL = CMP - CTL
    + PD1vsCMP = PD1 - CMP

# Running the analysis

## Initialization

### Load packages

```{r}
if (!require(maUEB)){
    require(devtools)
    install_github("uebvhir/maUEB", build_vignettes = FALSE)
}
```

### Set directories

```{r}
# Set working directory (it paths to vignette directory)
workingDir  <- here::here("vignettes")
# Parameters directory
paramDir <- file.path(workingDir, "parameters")
```

### Load global parameters

```{r}
source(file.path(paramDir, "global_parameters.par"))
```

For this example study, global parameters were set as follows:

```{r}
(global_parameters <- read.table(file.path(paramDir, "global_parameters.par"), header = FALSE, sep=";", as.is=TRUE))
```

### Set directories from parameters

```{r}
dataDir <- file.path(workingDir, dataDirN)
celDir <-  file.path(workingDir, celDirN)
resultsDir <- file.path(workingDir, resultsDirN)
```

### Targets preparation {#buildTargets}

The `build_targets()` function can be used to build a targets template dataframe that will then be manually filled. The targets template built will contain the filename of the arrays in rows and the variables of interest in columns.  First column (`FileName`) contains the names of the cel files contained in the celfiles directory specified in parameters. The remaining columns correspond to the descriptors specified in global parameters, among which there will be the following: `Group`,  `ShortName`, and `Colors`. Other variables may be `Batch`, `PatientID`, or other variables of interest that may be added by the user. The targets template built is saved as a semicolon-separated file named _targets.RSRCHR.STUDY.template.csv_, where `RSRCHR` refers to client acronym and `STUDY` refers to the study UEB id.

An example of the targets generated for this study is shown below:

```{r}
build_targets(inputDir=celDir, outputDir=dataDir, client=client, ID=ID, descriptors=descriptors)
```

```{r}
(targets_template <- read.table(file.path(dataDir, paste0("targets.", client, ".", ID, ".template.csv")), header = TRUE, sep = ";", as.is=TRUE))## Compte! la doble cometa l'interpreta com a accent greu si no es canvia a R) 
```

Then, the information for each descriptor needs to be filled manually in excel/libreoffice and saved as csv file _targets.RSRCHR.STUDY.csv_ using `;` as field separator.

## Block 01-Load-QC-Norm-Filt

### Load the parameters for this block

```{r}
#Parameters
source(file.path(paramDir, "01-Load-QC-Norm-Filt.par"))
#Execution parameters
source(file.path(paramDir, "01-Load-QC-Norm-Filt_analysistodo.par"))
```

For this example study, parameters were set as follows:

```{r}
(loadQCNormfilt_parameters <- read.table(file.path(paramDir, "01-Load-QC-Norm-Filt.par"), header = FALSE, sep=";", as.is=TRUE))
```

The execution parameters were set as follows:

```{r}
(loadQCNormfilt_todoparameters <- read.table(file.path(paramDir, "01-Load-QC-Norm-Filt_analysistodo.par"), header = FALSE, sep=";", as.is=TRUE))
```

### Load the targets file

Function `read_targets` reads the targets file specified in `targetsFN` (here _targets.RSRCHR.STUDY.csv_) that was generated in section \@ref(buildTargets). The cel file names contained in column `FileName` are set as rownames and factor variables specified by parameter `targets.fact` are converted to factors.

```{r}
(targets <- read_targets(inputDir=dataDir, targetsFN=targetsFN, targets.fact=targets.fact))
```

The targets contains `r nrow(targets)` rows and `r ncol(targets)` columns. A summary of the variables is shown below:

```{r}
summary(targets)
```

### Load raw data and create ExpressionSet object

Raw data can be read from the cel files or directly loaded from an existing Rda object ("rawData.Rda"). Function `read_celfiles()` reads the cel files listed in targets rownames (and in the same order) that are contained in the `celDir` directory and returns an object of class `ExpressionSet`.

```{r}
if (readcelFiles){
    eset_raw <- read_celfiles(inputDir=celDir, targets=targets)
    } else {if (loadRawData) {load(file.path(dataDir, "rawData.Rda"))}}
```

The `ExpressionSet` object contains the following fields:

* `assayData`: A matrix of expression values, where the rows represent probe sets (_features_) and columns represent samples. Row and column names must be unique, and consistent with row names of featureData and phenoData, respectively. The assay data can be retrieved with `exprs()`. Note that it can be subsetted though not reassigned. To reassign a new expression matrix one must create a new ExpressionSet.

* `phenoData`: An AnnotatedDataFrame containing information about each sample as defined in the targets file. The number of rows in phenoData must match the number of columns in assayData. Row names of phenoData must match column names of the matrix in assayData. The phenoData can be retrieved or assigned with `pData()`.

* `annotation`: A character describing the platform on which the samples were assayed. This is often the name of a Bioconductor chip annotation package. Can be retrieved or assigned with `annotation()`. For ClariomS/D it is automatically filled by the platform chip annotation.

```{r}
eset_raw
```

In this example study, the expression matrix of raw data contains `r nrow(exprs(eset_raw))` rows (features) and `r ncol(exprs(eset_raw))` columns (samples).

From now on, we will work with the `ExpressionSet` object `eset_raw`. This means that the phenotypic, annotation and expression data will be accessed from that object.

### Quality control (QC) of raw data

Performs different exploratory analyses (Boxplot, PCA, Heatmap of sample distances and hierarchical clustering) to inspect graphically the quality of samples from raw data. As well, a report of QC is generated using the array quality metrics package.

#### Boxplot of raw data

Creates a boxplot of log2-transformed intensity values from raw data and saves it as pdf into the results directory.

```{r}
if (boxplotRawData){
   qc_boxplot(data=eset_raw, group="Group", group.color="Colors", samplenames="ShortName", outputDir=resultsDir, label="RawData")
}
```

#### PCA of raw data

Performs a principal component analysis of raw data and creates different PCA plots with samples colored for each factor variable specified in 'pcaRawData.fact' from parameters. The PCA plot can be performed in 2 and/or 3 dimensions (representing the first 2 or 3 principal components) by setting the `dim` parameter. The loads (percentage of variance) cumulated for each of the principal components are returned.

```{r}
if (pcaRawData){
    loadsPCAraw <- qc_pca1(data=exprs(eset_raw), scale=pcaRawData.scale, pca2D_factors=pcaRawData.fact, targets=targets, col.group="Colors", colorlist=colorlist, names=targets$ShortName, outputDir=resultsDir, label="RawData")
}
```
```{r}
#si el volem en 3 dimensions:
if (pcaRawData){
    loadsPCAraw <- qc_pca1(data=exprs(eset_raw), pca3D=TRUE, scale=pcaRawData.scale, dim=c(1,2,3), pca3D_factors="Group", targets=targets, col.group="Colors", colorlist=colorlist, names=targets$ShortName, outputDir=resultsDir, label="RawData")
}
```

#### Heatmap of sample distances and hierarchical clustering of raw data

```{r}
if (heatmapRawData){
    qc_hc(data=exprs(eset_raw), hclust.method=hclustRawData.method, names=targets$ShortName, cexRow = 0.6, cexCol = 0.6, rect=TRUE, numclusters=2, outputDir=resultsDir, label="RawData")
}
```

#### ArrayQualityMetrics of raw data

```{r eval=FALSE}
#Note: Set 'intgroup' according to factors to be colored in heatmap. Other plots will be colored according to only the first factor
#required for Affymetrix QC
if (arrayQMRawData) {
    require(arrayQualityMetrics) 
    arrayQualityMetrics(eset_raw, outdir = file.path(resultsDir, "QCDir.Raw"), force=TRUE, intgroup=targets.fact)
}
```

### QC of raw data in one step

All the QC plots performed above can be performed in one step with function `qc_all`:

```{r}
qc_all(data=eset_raw, group="Group", group.color="Colors", samplenames="ShortName", factors=pcaRawData.fact, pca_scale=pcaRawData.scale, colorlist=colorlist, hc.method=hclustRawData.method, label="RawData", outputDir=resultsDir, summaryFN=resultsSummFN, doboxplot=TRUE, dopca=TRUE, dopvca=FALSE, dohc=TRUE, doarrayQMreport=FALSE)
```

### Normalization

Data can be normalized using `normalization()` function or directly loaded from an Rda object (`normData.Rda`) previously generated. The `normalization()` function normalizes raw data using one of the available methods (currently: rma method from oligo package). The RMA method allows background subtraction, quantile normalization and summarization (via median-polish) (ref). It returns a `FeatureSet` of normalized data and saves the normalized expression values in a datasheet (csv and/or xls file format) in the results folder. 

```{r}
if (loadNormData) {
    load(file.path(dataDir, "normData.Rda"))
} else if (normalizedata) {
    eset_norm <- normalization(data=eset_raw, norm.method="rma", annotPkg=annotPackage, outputFN="Normalized.All", outputDir=resultsDir)
}
```

### Save annotations of summarized probes

Constructs an aafTable object given a set of probe ids using `aafTableAnn` function from `annaffy` package. The dataframe with annotations is returned as an `aafTable` object and it also saves the annotation for all summarized probes as csv and html files. Note: in Exon studies, where probes are summarized at the probeset level but not transcript level, the probe annotations cannot be recovered using this function.

```{r eval=FALSE}
#no se pq dona error, nomes passa quan s'executa com a funcio sense haver previament carregat els paquets (?)
require(annotPackage, character.only=TRUE)
require(annaffy)
if (save_annot_all){normData_annot <- save_annotations(data=rownames(eset_norm), annotPkg=annotPackage, outputFN="Annotations.AllGenes", saveHTML=TRUE, title="Annotations for all genes", outputDir=resultsDir)}
```

### Quality control of normalized data

Here, the same functions used for quality control of raw data can be used to assess the quality of data after normalization. As an extra analysis, a PVCA (principal variance component analysis) can also be performed to further assess the source of batch effects in normalize data.

#### Boxplot of normalized data

Creates a boxplot of the normalized data (already in log2 scale) and saves it as pdf into the results directory.

```{r}
if (boxplotNormData){
   qc_boxplot(data=eset_norm, group="Group", col="Colors", names="ShortName", outputDir=resultsDir, label="NormData")
}
```

#### PCA of normalized data

Performs a principal component analysis of normalized data and creates different PCA plots with samples colored for each factor variable specified in 'pcaNormData.fact' from parameters. The loads (percentage of variance) cumulated for each of the principal components are returned.

```{r}
if (pcaNormData){
    loadsPCAnorm <- qc_pca1(data=exprs(eset_norm), scale=pcaNormData.scale, pca2D_factors=pcaNormData.fact, targets=targets, col.group="Colors", colorlist=colorlist, names=targets$ShortName, outputDir=resultsDir, label="NormData")
}
```

If there are batch effects, the PCA can be repeated removing the batch effects using the `removeBatchEffect` function from `limma` package. Here this step is performed only for illustration purposes, since the `Batch` variable is artificial. We use the same function as for the PCA but specify `batchRemove=TRUE` and the name of `Batch` variable in `batchFactors` parameter.

```{r}
if (pcaNormData.corrbatch){
    loadsPCAnorm.corrbatch <- qc_pca1(exprs(eset_norm), scale=pcaNormData.scale, pca2D_factors=pcaNormData.fact, targets=targets, col.group="Colors", colorlist=colorlist, names=targets$ShortName, outputDir=resultsDir, label="NormData", batchRemove=TRUE, batchFactors="Batch", size = 1.5, glineas = 0.25)
}
```

#### Heatmap of sample distances and hierarchical clustering of normalized data

```{r}
if (heatmapNormData){
    qc_hc(data=exprs(eset_norm), hclust.method=hclustNormData.method, names=targets$ShortName, cexRow = 0.6, cexCol = 0.6, rect=TRUE, numclusters=2, outputDir=resultsDir, label="NormData")
}
```

#### ArrayQualityMetrics of normalized data

```{r eval=FALSE}
#Note: Set 'intgroup' according to factors to be colored in heatmap. Other plots will be colored according to only the first factor
require(arrayQualityMetrics) #required for Affymetrix QC
if (arrayQMNormData) arrayQualityMetrics(eset_norm, outdir = file.path(resultsDir, "QCDir.Norm"), force=TRUE, intgroup=targets.fact)
```

#### PVCA of normalized data 

The PVCA approach can be used as a screening tool to determine which sources of variability (biological, technical or other) are most prominent in a given microarray data set.

```{r message=FALSE}
if (pvcaNormData){
    qc_pvca(data=eset_norm, factors=pvcaNormData.fact, targetsPVCA=targets.pvcaFN, pct_threshold=pct_threshold, label="NormData", outputDir=resultsDir, summaryFN=resultsSummFN)
}
```

### QC of normalized data in one step

All the QC plots performed above can be performed in one step with function `qc_all`:

```{r}
qc_all(data=eset_norm, group="Group", group.color="Colors", samplenames="ShortName", factors=pcaNormData.fact, factorspvca=pvcaNormData.fact, pca_scale=pcaNormData.scale, colorlist=colorlist, hc.method=hclustNormData.method, label="NormData", outputDir=resultsDir, summaryFN=resultsSummFN, doboxplot=TRUE, dopca=TRUE, dopvca=TRUE, dohc=TRUE, doarrayQMreport=FALSE)
```

### Sample exclusion

The Quality Control may reveal some outlier samples that should be removed before proceeding with the differential expression analysis. Here, sample `CMP.2` appears as a putative outlier both in the hierarchical clustering and PCA analysis. Therefore, this sample will be discarded from the analysis. 

To remove samples, the whole ExpressionSet object can be subsetted as follows:

```{r}
samplestoremove <- "CMP.2"
eset_raw.f <- eset_raw[,-which(colnames(eset_raw)%in%samplestoremove)]
dim(eset_raw)
dim(eset_raw.f)
```
Note that the phenoData contained in that object has also been subsetted:

```{r}
pData(eset_raw.f)
targets.f <- pData(eset_raw.f)
```

After sample removal, the whole QC and normalization process should be repeated without those samples.

Hence, data is normalized with the new dataset (here we don't change the `outputFN` parameter so that files _Normalized.All.xls_ and _Normalized.All.csv_ are overwritten):

```{r}
eset_norm.f <- normalization(data=eset_raw.f, norm.method="rma", annotPkg=annotPackage, outputFN="Normalized.All", outputDir=resultsDir)
```

The QC is performed again with the normalized data after sample exclusion. We will indicate that the plots correspond to the dataset after sample exclusion by adding `.f` in `label` parameter:

```{r}
qc_all(data=eset_norm.f, group="Group", group.color="Colors", samplenames="ShortName", factors=pcaNormData.fact, factorspvca=pvcaNormData.fact, pca_scale=pcaNormData.scale, colorlist=colorlist, hc.method=hclustNormData.method, label="NormData.f", outputDir=resultsDir, summaryFN=resultsSummFN, doboxplot=TRUE, dopca=TRUE, dopvca=FALSE, dohc=TRUE, doarrayQMreport=FALSE)
```

If there were batch effects, we should also repeat the PCA removing batch effects with the new dataset:

```{r}
loadsPCAnorm.f.corrbatch <- qc_pca1(exprs(eset_norm.f), scale=pcaNormData.scale, pca2D_factors=pcaNormData.fact, targets=targets.f, col.group="Colors", colorlist=colorlist, names=targets.f$ShortName, outputDir=resultsDir, label="NormData.f", batchRemove=TRUE, batchFactors="Batch", size = 1.5, glineas = 0.25)
```

### Filtering

<!-- A revisar.  -->

Some filtering can be performed prior to differential expression analysis to remove the affymetrix control probes, as well as probesets with missing or duplicate _EntrezID_ (annotation-based filtering); and/or to remove probesets with low variance (variance-based filtering). These options are specified in the following parameters: `filtByAnnot` and `filtByVar`, respectively. The resulting object is named `eset_filt`.

#### SD plot

Function `sdplot()` can be used to plot the standard deviations of all probesets in the array.

```{r}
if (SDplot){
    sdplot(data=exprs(eset_norm.f), var_thr=filterByVar.thr, label="NormData", outputDir=resultsDir)
}
```

#### Filtering of normalized data

```{r}
eset_filtered <- filtering(data=eset_norm.f, outputFN="Normalized.Filtered", outputDir=resultsDir, summaryFN=resultsSummFN,
                           feature.exclude="^AFFX",require.entrez=filterByAnnot, remove.dupEntrez = filterByAnnot,
                           var.filter=filterByVar, var.func = filterByVar.fun, var.cutoff = filterByVar.thr, filterByQuantile=TRUE,
                           require.GOBP = FALSE, require.GOCC = FALSE, require.GOMF = FALSE)
dim(eset_filtered)
```

#### Save annotations of filtered data

```{r eval=TRUE}
#no se pq dona error, (Error: no such table: go.go_term) nomes passa quan s'executa com a funcio sense haver previament carregat els paquets (?)
require(annotPackage, character.only=TRUE)
require(annaffy)
if (save_annot_filt){normData.filt_annot <- save_annotations(data=rownames(eset_filtered), annotPkg=annotPackage, outputFN="Annotations.Filtered", saveHTML=TRUE, title="Annotations for filtered genes", outputDir=resultsDir)}
```

### Save data from this block (normData.Rda object)

```{r}
# When you save your data, use save(MyObject, file = "MyObject.RData", version = 2) to maintain back-compatibility and avoid the warning. (otherwise, others using R < 3.5.0 won't be able to load your saved files.)

if (!is.null(samplestoremove)){
    if (normalizedata) {
            save(eset_raw, eset_norm, eset_raw.f, eset_norm.f, eset_filtered, targets, targets.f, file=file.path(dataDir,"normData.Rda"), version=2)
        } else {
            save(eset_raw, eset_raw.f, targets, targets.f, file=file.path(dataDir,"rawData.Rda"), version=2)
        }
    } else {
          if (normalizedata) {
            save(eset_raw, eset_norm, eset_filtered, targets, file=file.path(dataDir,"normData.Rda"), version=2)
        } else {
            save(eset_raw, targets, file=file.path(dataDir,"rawData.Rda"), version=2)
        }
        }
```

## Block 02-Differential Expression Analysis (DEA)

### Background

The analysis to select differentially expressed genes will be based on adjusting a linear model with empirical Bayes moderation of the variance. This is a technique specifically developed for microarray data analysis by Gordon K Smyth @smyth2004. Linear modeling is the same as ordinary analysis of variance or multiple regression except that a model is fitted for every gene. Of note, limma estimates the gene-specific variance using information from all samples in all groups, even if not all groups participate in the pairwise comparisons. This is necessary in 'omics studies with limited replication, and outweighs any supposed disadvantage of differences in variances between groups. For statistical analysis and assessing differential expression, limma uses an empirical Bayes method to moderate the standard errors of the estimated log-fold changes. This results in more stable inference and improved power, especially for experiments with small numbers of arrays.

The main purpose of fitting a linear model to the data is to estimate the variability in the data, hence the _systematic_ part needs to be modelled so it can be distinguished from _random_ variation. The model is specified by the _design matrix_. Each row of the design matrix corresponds to an array in your experiment and each column corresponds to a coefficient that is used to describe the RNA sources in your experiment. Then, a contrasts step is performed so that you can take the initial coefficients and compare them in as many ways as you want to answer any questions you might have, regardless of how many or how few these might be. (ref: limma user's guide)

General recommendations:

*  Since limma estimates the gene-specific variance using information from all samples in all groups, the design matrix should be constructed with all the samples (arrays) of the experiment, even if not all groups participate in the pairwise comparisons. However, some exceptions where subsetting could be reasonable could be when two groups are very different (eg. different tissues)
* The covariates included in the linear model should not be correlated (eg. if the `Group` variable already integrates the information of `Sex`, no additional `Sex` covariate should be added to the model). Adding correlated variables may cause the design matrix to be unranked.
* If batch effects were detected during Quality Control, the `Batch` variable should be added to the model as a systematic blocking factor
* When samples are derived from the same Subject, this could be taken into account as a random or systematic effect. In general, with well balanced designs, including the Subject as a systematic blocking factor is recommended (paired analysis). For unbalanced designs or to make comparisons both within and between subjects, it is necessary to treat Subject as a random effect. This can be done in limma using the duplicateCorrelation function. (ref. limma user's guide chapter 9.7)

References on how to build design matrices: 

* [limma user's guide](https://www.bioconductor.org/packages/devel/bioc/vignettes/limma/inst/doc/usersguide.pdf)
* vignette from edgeR package [design matrices.html](https://bioconductor.org/packages/release/workflows/vignettes/RNAseq123/inst/doc/designmatrices.html#interaction-using-a-single-factor-model)

### Load the parameters for this block and set directories

```{r}
#Parameters
source(file.path(paramDir, "02-DEA.par"))
#Execution parameters
source(file.path(paramDir, "02-DEA_analysistodo.par"))
```

For this example study, parameters were set as follows:

```{r}
(loadDEA_parameters <- read.table(file.path(paramDir, "02-DEA.par"), header = FALSE, sep=";", as.is=TRUE))
```

The execution parameters were set as follows:

```{r}
(loadDEA_todoparameters <- read.table(file.path(paramDir, "02-DEA_analysistodo.par"), header = FALSE, sep=";", as.is=TRUE))
```

Since directories could change from block to block, we set them again for this block:

```{r}
dataDir <- file.path(workingDir, dataDirN)
resultsDir <- file.path(workingDir, resultsDirN)
```

### Data for DEA

The Rda file generated in _Block 01-Load-QC-Norm-Filt_ will be used as input for DEA:

```{r}
load(file.path(dataDir, inputDEARda)) 
```

We assign the `ExpressionSet` object to be used for the analysis to an R object (it is specified in the `eset_analysis` parameter as a string)

```{r}
eset_analysis <- eval(parse(text=eset_analysis))
```

### Building the linear model

#### Design matrix

The design matrix is created from the phenotypic data, which can be retrieved from the `ExpressionSet` object using `pData(eset_analysis)` or from the `targets` object. The safer way is to work with the `ExpressionSet` object, instead of using the expression data and targets file separately. Note that it constructs the design matrix based only on targets sample name and then the fit is done based on the indexed positions.

Function `dea_lmdesign()` can be used to construct a design matrix. The main factor representing the _Group_ of treatment should be provided in `group` parameter, and the covariates or systematic effects to take into account will be introduced in the `covariates` parameter. The design matrix will be constructed according to the formula `~ 0 + group + covariates`. This design is the most optimal and flexible to enable different comparisons specified by the contrasts matrix. However, alternative designs can also be created by providing a formula to the `fmla` parameter. 

In addition, if random effects are to be taken into account, this will be specified in `blocking.fact` parameter and taken into account via `duplicateCorrelation()` function during the model fit (see next section). 

In this example, the artificially created `Batch` factor will be added to the model for illustration purposes only. 

```{r}
#parameters specified in file 02-DEA.par:
design.mainfact
design.cofact
blocking.fact
```

```{r}
(design <- dea_lmdesign(targets=pData(eset_analysis), sampleNames="ShortName", data=eset_analysis,
                     group=design.mainfact, cov.fact=design.cofact, cov.num=design.num, fmla=NULL, 
                     summaryFN=resultsSummFN, outputDir=resultsDir))
```

#### Linear model fit

Function `dea_lmfit()` can be used to fit the linear model to the data, as specified by the design matrix. It uses `lmFit` function from `limma` package. If random effects are to be taken into account, this should be specified in the `block.cor` parameter  (i.e. `blocking.fact` parameter is not null), the correlation between measurements made on the same block will be estimated using `duplicateCorrelation` function from `limma` package and used to fit to the model. The calculated correlation consensus can be accessed from the object `fit` returned (`fit$correlation`).

```{r}
fit <- dea_lmfit(data=eset_analysis, targets=pData(eset_analysis), design=design, block.cor=NULL, summaryFN=resultsSummFN, outputDir=resultsDir)
```

### Compute the contrasts and moderated t-tests

The contrasts to be computed are defined in `contrastsv` parameter of `02-DEA.par` file, where the contrasts names will be the coefficients to be extracted from the `fit` object. Function `dea_compare()` allows to construct the contrast matrix and compute estimated coefficients and standard errors for the given set of contrasts. In addition, it performs an empirical Bayes moderation of the standard errors. In the case where no moderation of the standard errors is to be performed (not recommended), this can be achieved by specifying `moderated=FALSE` parameter. The object returned `fit.main`.

```{r}
fit.main <- dea_compare(fit=fit, contrasts=contrastsv, design=design, moderated=TRUE, summaryFN=resultsSummFN, outputDir=resultsDir)
```

```{r}
names(fit.main)
```


### TopTables

Assign name of comparisons (contrasts) to `listofcoef` variable:

```{r}
(listofcoef <- colnames(fit.main))
```

Function `dea_toptab` allows to obtain the toptables for the comparisons analyzed. To create html tables use `html_report`=TRUE (it will spend more time in execution).

```{r}
#versio amb les html tables com venen per defecte (nomes mostra adj pval o pval)
listofcsv <- dea_toptab(listofcoef=listofcoef, fit.main=fit.main, eset=eset_analysis, padjust.method="fdr", 
                        html_report=ReportHTMLTopTab, 
                        html_ntop=500, html_group="Group", html_padjust_method = toptable_padjust_method,
                        outputDir=resultsDir)
head(listofcsv[[1]])
```

```{r eval=FALSE}
#versio amb les html tables modificades pq mostriin tots els estadistics. No l'executo pq triga molt. A millorar
listofcsv <- dea_toptab1(listofcoef=listofcoef, fit.main=fit.main, eset=eset_analysis, padjust.method="fdr", 
                        html_report=TRUE, #ReportHTMLTopTab, 
                        html_ntop=500, html_group="Group", 
                        outputDir=resultsDir)
names(listofcsv)
head(listofcsv[[1]])
```



### Results summary

Function `dea_summary_ngc` can be used to summarize the results of differential expression. It returns a table with the number of features that are differentially expressed under different statistical thresholds. They are catalogued as _Up_ or _Down_-regulated if their logFC is above or below a selected logFC threshold, respectively. 

```{r}
(numGenesChanged <- dea_summary_ngc(listofcoef=listofcoef, listofcsv=listofcsv, B_thr=c(0), Pval_thr=c(0.01,0.05,0.1), adjPval_thr=c(0.01,0.05,0.15,0.25), logFC_thr=0, outputDir=resultsDir))
```

For an extended table involving different logFC thresholds, use function `dea_summary_ngc_ext` instead. The output will be a list with the summary tables obtained for each comparison.

```{r}
ngc_list <- dea_summary_ngc_ext(listofcoef=listofcoef, listofcsv=listofcsv, B_thr.e=c(0), Pval_thr.e=c(0.01,0.05,0.1), adjPval_thr.e=c(0.01,0.05,0.15,0.25), logFC_thr.e=c(0,0.5,1,1.5,2), outputDir=resultsDir)
names(ngc_list)
head(ngc_list[["PD1vsCTL"]])
```

The two functions mentioned above are combined into a single function `dea_summary_ngc1`, where parameter `extended` specifies whether the extended tables are to be performed. The output is a list of two elements, the first containing the simple numGenesChanged dataframe and the second a list with the extended tables if performed.

```{r}
numGenesChanged_all <- dea_summary_ngc1(listofcoef=listofcoef, listofcsv=listofcsv, B_thr=c(0), Pval_thr=c(0.01,0.05,0.1), adjPval_thr=c(0.01,0.05,0.15,0.25), logFC_thr=0, extended=TRUE, B_thr.e=c(0), Pval_thr.e=c(0.01,0.05,0.1), adjPval_thr.e=c(0.01,0.05,0.15,0.25), logFC_thr.e=c(0,0.5,1,1.5,2), outputDir=resultsDir)
names(numGenesChanged_all)
```

### Volcano plots

The results of the differential expression analysis obtained for each comparison can be visualized in a volcano plot using `dea_volcanoplot()` function. The volcano plot is a type of scatterplot that shows statistical significance (P value) versus magnitude of change (fold change). It enables quick visual identification of genes with large fold changes that are also statistically significant. The top significant genes are shown in purple according to the thresholds of logFC and pvalue specified in parameters `volc_logFC`, `volc_pval` and `volc_pval.thr`, with defaults set to an absolute logFoldChange above 1 and adjusted p-value below 0.05. In addition, Gene symbols are shown for the most significant genes, with a maximum of 20. The plots are saved as pdf into the `outputDir` specified and shown in the graphical device.

```{r }
dea_volcanoplot(listofcsv=listofcsv, listofcoef=listofcoef, volc_logFC=rep(1,length(listofcoef)), volc_pval=c(rep("adj.P.Val", length(listofcoef))), volc_pval.thr=rep(0.05, length(listofcoef)), volc_x0=rep(-3, length(listofcoef)), volc_x1=rep(+3, length(listofcoef)), volc_y0=rep(0, length(listofcoef)), volc_y1=rep(10, length(listofcoef)), n=6, cols=2, outputDir=resultsDir, label="")
```

### All DEA in one function

All the steps performed in `Block 02- DEA` can be executed in a single step using `dea_all1()` function. The result is a list with objects corresponding to each step of the analysis:

```{r}
dea.results <- dea_all(data=eset_analysis, targets=pData(eset_analysis), sampleNames="ShortName", group=design.mainfact, cov.fact=design.cofact, cov.num=design.num, fmla=NULL, block.cor=blocking.fact, contrastsv=contrastsv, moderated=TRUE, padjust.method="fdr", html_report=FALSE, html_ntop=500, html_group="Group", B_thr=c(0), Pval_thr=c(0.01,0.05,0.1), adjPval_thr=c(0.01,0.05,0.15,0.25), logFC_thr=0, extended=TRUE, B_thr.e=c(0), Pval_thr.e=c(0.01,0.05,0.1), adjPval_thr.e=c(0.01,0.05,0.15,0.25), logFC_thr.e=c(0,0.5,1,1.5,2), dovolcanoplot=TRUE, volc_logFC=rep(1,length(contrastsv)), volc_pval=c(rep("adj.P.Val", length(contrastsv))), volc_pval.thr=rep(0.05, length(contrastsv)), volc_x0=rep(-3, length(contrastsv)), volc_x1=rep(+3, length(contrastsv)), volc_y0=rep(0, length(contrastsv)), volc_y1=rep(10, length(contrastsv)), n=6, cols=2, label="", summaryFN=resultsSummFN, outputDir=resultsDir)
```

```{r}
names(dea.results)
dea.results$fit.main$design
dea.results$fit.main$contrasts
#extract objects for further analysis:
fit.main <- dea.results$fit.main
listofcsv <- dea.results$listofcsv
numGenesChanged_all <- dea.results$numGenesChanged
```

```{r}    
save(listofcoef, listofcsv, eset_norm, eset_analysis, targets, file=file.path(dataDir,"afterTopTabs.Rda"), version=2)
```


## Block 03 Analysis of Multiple Comparisons

### Background

It is interesting to look for common patterns of regulation between different experimental conditions. In order to find the degree of overlapped genes among different comparisons, a multiple comparisons analysis has been performed. Venn diagrams and heatmaps have been plotted for the different multiple comparisons. 

### Load the parameters for MC analysis and set directories

```{r}
#Parameters
source(file.path(paramDir, "03-MC.par"))
#Execution parameters
source(file.path(paramDir, "03-MC_analysistodo.par"))
```

For this example study, parameters were set as follows:

```{r}
(loadMC_parameters <- read.table(file.path(paramDir, "03-MC.par"), header = FALSE, sep=";", as.is=TRUE))
```

```{r}
(loadMC_todoparameters <- read.table(file.path(paramDir, "03-MC_analysistodo.par"), header = FALSE, sep=";", as.is=TRUE))
```

Since directories could change from block to block, we set them again for this block:

```{r}
dataDir <- file.path(workingDir, dataDirN)
resultsDir <- file.path(workingDir, resultsDirN)
rdaDir <- dataDir
```

### Data for MC

The Rda file generated in _Block 02-Differential Expression Analysis (DEA)_  will be used as input for MC:

```{r}
load(file.path(dataDir, inputMCRda))
```

### MC Venn Upset

Function `mc_venn_upset()` can be used to perform Venn diagrams and/or Upset plots for the comparisons analyzed.

```{r results='asis'}
listsharedelems <- lapply(seq_along(venn_comparNames), function(v) {
  setwd(resultsDir)
  namescomp <- names(listofcsv)[venn_compar[[v]]]
  listsharedelems <- mc_venn_upset(listofcsv=listofcsv, namescomp=namescomp, label = venn_comparNames[v], colFeat = colFeat[v], 
                            colPval = venn_pval[v], pval = venn_pval.thr[v], colFC=venn_FC_col[v], FC=venn_FC.thr[v], include=venn_include[v], pltR = TRUE, 
                            pltPdf = TRUE, pltPng=FALSE, venn = TRUE, eul = FALSE, saveTables = TRUE, upsetPlot=FALSE,
                            saveTables_extended=Venn_sharedElems_extended,
                            colors = rainbow(length(namescomp)), trans = 0.5, 
                            cex1 = 1, rotation=0, position=venn_pos[[v]], cex2 = 1, resultsSummFN=resultsSummFN, outputDir=resultsDir)
  setwd(workingDir)
  return(listsharedelems)
})
names(listsharedelems) <- venn_comparNames
```

```{r}
knitr::include_graphics(file.path(resultsDir, "VennDiagram.abs.EffectTreatment.adj.P.Val0.05.logFC1.pdf"))
```

### MC Heatmap plots

Function `mc_hm()` can be used to perform Heatmap plots for the comparisons analyzed.

```{r}
mc_hm(listofcsv=listofcsv, hm_dataset=listofcsv[[1]], targets=targets.f, featureCol=featureCol, hm_comparNames=hm_comparNames, hm_compar=hm_compar, hm_groupexclude=hm_groupexclude, hm_pval=hm_pval, hm_pval.thr=hm_pval.thr, hm_logFC=hm_logFC, hm_logFC.thr=hm_logFC.thr, hm_palette=hm_palette, hm_clustCol=hm_clustCol, hm_clustCol.dist=hm_clustCol.dist, hm_clustCol.method=hm_clustCol.method, hm_clustRow.cor=hm_clustRow.cor, batcheffect=batcheffect, batchcolName=batchcolName, batchcolName2=batchcolName2, batchNumcolName=batchNumcolName, hm_plots_interactive=TRUE, resultsSummFN=resultsSummFN, outputDir=resultsDir)
```

<!-- ### All MC in one -->

<!-- All the steps performed in Block 03- MC can be executed in a single step using mc_all() function. The result are the Venn and the Heatmaps plots generated. -->

<!-- ```{r} -->
<!-- mc_all(listofcsv=listofcsv, namescomp=namescomp, label = venn_comparNames, colFeat = colFeat, -->
<!--                             colPval = venn_pval, pval = venn_pval.thr, colFC=venn_FC_col, FC=venn_FC.thr, include=venn_include, pltR = FALSE, -->
<!--                             pltPdf = TRUE, pltPng=FALSE, venn = TRUE, eul = FALSE, saveTables = TRUE, upsetPlot=FALSE, -->
<!--                             saveTables_extended=Venn_sharedElems_extended, colors = rainbow(length(namescomp)), hm_comparNames=hm_comparNames, hm_compar=hm_compar,       hm_groupexclude=hm_groupexclude, hm_pval=hm_pval, hm_pval.thr=hm_pval.thr, hm_logFC=hm_logFC, hm_palette=hm_palette,                                           hm_clustCol=hm_clustCol, hm_clustCol.dist=hm_clustCol.dist, hm_clustCol.method=hm_clustCol.method, hm_clustRow.cor=hm_clustRow.cor,                             batcheffect=batcheffect, batcheffect2=batcheffect2, batcheffect3=batcheffect3, batchcolName=batchcolName, batchcolName2=batchcolName2, batchcolName3=batchcolName3, resultsSummFN=resultsSummFN, outputDir=resultsDir) -->
<!-- ``` -->

## Block 04 A-Analysis of Biological Significance (ABS-GSEA)

### Background

The analysis of biological significance has been based on gene set enrichment analysis (GSEA) @Subramanian2005 on different annotation databases. The analysis has been performed over two annotation databases: the "Gene Ontology" (GO) and the Reactome Pathway Knowledge base @reactome:2018. The goal of this analysis is to perform one of the available statistical tests to determine whether a given _Gene Set_, usually a particular category of the GO or pathway in Reactome, is over-represented in the list of selected genes (the _sample_) with respect (i.e. compared) to a reference set (the _population_) from where it has been selected. The reference set is usually taken to be all the genes analyzed in the study. In GSEA, all the genes analyzed in the study ( _filtered genes_) are ranked by log fold change an used in the analysis. GSEA aggregates the per gene statistics across genes within a gene set, therefore making it possible to detect situations where all genes in a predefined set change in a small but coordinated way @Subramanian2005.

### Load the parameters for ABS-GSEA and set directories

```{r}
#Parameters
source(file.path(paramDir, "04-ABS-GSEA.par"))
#Execution parameters
source(file.path(paramDir, "04-ABS-GSEA_analysistodo.par"))
```

For this example study, parameters were set as follows:

```{r}
(loadABSGSEA_parameters <- read.table(file.path(paramDir, "04-ABS-GSEA.par"), header = FALSE, sep=";", as.is=TRUE))
```

```{r}
(loadABSGSEA_todoparameters <- read.table(file.path(paramDir, "04-ABS-GSEA_analysistodo.par"), header = FALSE, sep=";", as.is=TRUE))
```

Since directories could change from block to block, we set them again for this block:

```{r}
dataDir <- file.path(workingDir, dataDirN)
resultsDir <- file.path(workingDir, resultsDirN)
rdaDir <- dataDir
gmtDir <- resultsDir
```

### Data for ABS-GSEA

The Rda file generated in _Block 02-Differential Expression Analysis (DEA)_  will be used as input for GSEA:

```{r}
load(file.path(dataDir, inputABSGSEARda))
```

### GO unfilt GSEA

Function `abs_gsea_GOunfilt()` can be used to perform GO analysis for all the comparisons and store unfiltered results (no pvalue threshold) in lists. The necessary inputs are the toptables generated in the DEA analysis and as output, the analysis will give you lists of GO unfiltered results and a table with number of terms found at different pvalue thresholds for the different categories analyzed.

```{r}
namescomp <- names(listofcsv)[GO_comparisons]
```

```{r eval=FALSE}
GSEA_GOresults.unfilt <- abs_gsea_GOunfilt(listofTopNamed=listofcsv, namescomp=namescomp, annotPackage=annotPackage, organism_annot= organism_annot, ranking_metric=ranking_metric, geneColname=geneColname, keyType=keyType, GO_minSetSize=GO_minSetSize, GO_maxSetSize=GO_maxSetSize, resultsSummFN=resultsSummFN, saveRda=saveRda, saveGMT=saveGMT, label=label, outputDir=resultsDir, rdaDir=rdaDir, gmtDir=gmtDir)
  
```

### GO filt GSEA plots

Function `abs_gsea_GOfiltplot()` filters GO results according to the pvalue threshold set previously in parameters. It takes as input the lists of GO unfiltered results and pvalue thresholds. As an output, dataframes of GO results filtered by pvalue are obtained. The function also performs a GO significance analysis, giving some plots with the most enriched GO terms pathways. 


```{r eval=FALSE}
GSEA_GOresults.filt <- abs_gsea_GOfiltplot(GSEAresGO=GSEA_GOresults.unfilt, GO_pvalcutoff=GO_pvalcutoff, GO_pAdjustMethod=GO_pAdjustMethod, saveTables=saveTables, GOPlots=GOPlots, label=label, resultsSummFN=resultsSummFN, outputDir=resultsDir)
```

### Reactome pathways unfilt GSEA

Function `abs_gsea_ReactomePAunfilt()` can be used to perform Reactome analysis for all the comparisons and store unfiltered results (no pvalue threshold) in lists. The necessary inputs are the toptables generated in the DEA analysis and as output, the analysis will give you lists of Reactome unfiltered results and a table with number of terms found at different pvalue thresholds for the different categories analyzed.


```{r eval=FALSE}
namescomp <- names(listofcsv)[Reac_comparisons]
GSEA_ReactomePA.unfilt <- abs_gsea_ReactomePAunfilt(listofTopNamed=listofcsv, namescomp=namescomp, organism=organism, organism_annot=organism_annot, Reac_minSetSize=Reac_minSetSize, Reac_maxSetSize=Reac_maxSetSize, resultsSummFN=resultsSummFN, saveRda=saveRda, saveGMT=saveGMT, label=label, outputDir=resultsDir, rdaDir=rdaDir, gmtDir=gmtDir)
```

### Reactome filt GSEA plots

Function `abs_gsea_ReactomePAfiltplot()` filters Reactome results according to the pvalue threshold set previously in parameters. It takes as input the lists of Reactome unfiltered results and pvalue thresholds. As an output, dataframes of Reactome results filtered by pvalue are obtained. The function also performs a Reactome significance analysis, giving some plots with the most enriched Reactome pathways. 

```{r eval=FALSE}
abs_gsea_ReactomePAfiltplot(GSEAresReac=GSEA_ReactomePA.unfilt, Reac_pvalcutoff=Reac_pvalcutoff, Reac_pAdjustMethod=Reac_pAdjustMethod, saveTables=saveTables, ReacPlots=ReactomePlots, label=label, resultsSummFN=resultsSummFN, outputDir=resultsDir)
```


## Block 04 B-Analysis of Biological Significance (ABS-ORA)

### Background

An overrepresentation analysis (ORA) will be performed over GO-BP and Reactome Pathways databases to find the terms enriched in the lists of genes up-regulated/down-regulated in common between the comparisons analyzed.

### Load the parameters for ABS-ORA and set directories

```{r}
#Parameters
source(file.path(paramDir, "04-ABS-ORA.par"))
#Execution parameters
source(file.path(paramDir, "04-ABS-ORA_analysistodo.par"))
```

For this example study, parameters were set as follows:

```{r}
(loadABSORA_parameters <- read.table(file.path(paramDir, "04-ABS-ORA.par"), header = FALSE, sep=";", as.is=TRUE))
```

```{r}
(loadABSORA_parameters <- read.table(file.path(paramDir, "04-ABS-ORA_analysistodo.par"), header = FALSE, sep=";", as.is=TRUE))
```

Since directories could change from block to block, we set them again for this block:

```{r}
dataDir <- file.path(workingDir, dataDirN)
resultsDir <- file.path(workingDir, resultsDirN)
rdaDir <- dataDir
gmtDir <- resultsDir
```

### Data for ABS-ORA

The Rda file generated in _Block 02-Differential Expression Analysis (DEA)_  will be used as input for ABS-ORA:

```{r}
load(file.path(dataDir, inputABSORARda))
```

### GO unfilt ORA

Function `abs_ora_GOunfilt()` can be used to perform an overrepresentation GO analysis for all the comparisons and store unfiltered results (no pvalue threshold) in lists. The necessary inputs are the toptables generated in the DEA analysis and as output, the analysis will give you lists of GO unfiltered results and a table with number of terms found at different pvalue thresholds for the different categories analyzed.

```{r ORA_GOunfilt, eval=FALSE}
ORA_GOresults.unfilt <- abs_ora_GOunfilt(listofTopNamed=listofcsv, namescomp=namescomp, universe=universe, geneColname=geneColname, readable=readable, selected.pval.go=selected.pval.go, selected.pvalthr.go=selected.pvalthr.go, selected.logFC.go=selected.logFC.go, col_logFC.go=col_logFC.go, sign_logFC.go=sign_logFC.go, organism_annot=organism_annot, keyType=keyType, GO_categories=GO_categories, GO_minSetSize=GO_minSetSize, GO_maxSetSize=GO_maxSetSize, resultsSummFN=resultsSummFN, saveRda=saveRda, saveGMT=saveGMT, label=label, outputDir=resultsDir, rdaDir=rdaDir, gmtDir=gmtDir)
```

### GO filt ORA plots

Function `abs_ora_GOfiltplot()` filters GO results according to the pvalue threshold set previously in parameters. It takes as input the lists of GO unfiltered results and pvalue thresholds. As an output, dataframes of GO results filtered by pvalue are obtained. The function also performs a GO significance analysis, giving some plots with the most enriched GO terms pathways. 

```{r ORA_GOanalysis_filt, eval=FALSE}
ORA_GOresults.filt <- abs_ora_GOfiltplot(ORAresGO=ORA_GOresults.unfilt, sign=sign, GO_pvalcutoff=GO_pvalcutoff, GO_pAdjustMethod=GO_pAdjustMethod, saveTables=saveTables, GOPlots=GOPlots, label=label, resultsSummFN=resultsSummFN, outputDir=resultsDir)
```

### Reactome unfilt ORA

Function `abs_ora_ReactomePAunfilt()` can be used to perform an overrepresentation Reactome analysis for all the comparisons and store unfiltered results (no pvalue threshold) in lists. The necessary inputs are the toptables generated in the DEA analysis and as output, the analysis will give you lists of Reactome unfiltered results and a table with number of terms found at different pvalue thresholds for the different categories analyzed.

```{r ORA_ReactomePAanalysis_unfilt, eval=FALSE}
ORA_ReactomePAresults.unfilt <- abs_ora_ReactomePAunfilt(listofTopNamed=listofcsv, namescomp=namescomp, universe=universe, col_entrez=col_entrez, readable=readable, selected.pval.reac=selected.pval.reac, selected.pvalthr.reac=selected.pvalthr.reac, selected.logFC.reac=selected.logFC.reac, col_logFC.reac=col_logFC.reac, sign_logFC.reac=sign_logFC.reac, organism=organism, organism_annot=organism_annot, keyType=keyType, Reac_minSetSize=Reac_minSetSize, Reac_maxSetSize=Reac_maxSetSize, resultsSummFN=resultsSummFN, saveRda=saveRda, saveGMT=saveGMT, label=label, outputDir=resultsDir, rdaDir=rdaDir, gmtDir=gmtDir)
```

### Reactome filt ORA plots

Function `abs_ora_ReactomePAfiltplot()` filters Reactome results according to the pvalue threshold set previously in parameters. It takes as input the lists of Reactome unfiltered results and pvalue thresholds. As an output, dataframes of Reactome results filtered by pvalue are obtained. The function also performs a Reactome significance analysis, giving some plots with the most enriched Reactome pathways. 

```{r ORA_ReactomePAanalysis_filt, eval=FALSE}
ORA_ReactomePAanalysis_filt <- abs_ora_ReactomePAfiltplot(ORAresReac=ORA_ReactomePAresults.unfilt, sign=sign, Reac_pvalcutoff=Reac_pvalcutoff, Reac_pAdjustMethod=Reac_pAdjustMethod, saveTables=saveTables, ReacPlots=ReacPlots, label=label, resultsSummFN=resultsSummFN, outputDir=resultsDir)
```


<!-- # Special cases -->

<!-- ## Different tissues -->

<!-- ## Paired analysis -->

# References
